{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_id</th>\n",
       "      <th>bounding_boxes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/A_001.jpg</td>\n",
       "      <td>0 225 214 317 0 172 345 254 285 240 155 131 70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/A_002.jpg</td>\n",
       "      <td>0 254 190 293 0 169 338 271 276 238 160 137 70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/A_003.jpg</td>\n",
       "      <td>0 306 59 241 0 155 306 318 235 233 191 149 713...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/A_004.jpg</td>\n",
       "      <td>0 143 239 298 164 223 240 172 721 293 94 76 57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/A_005.jpg</td>\n",
       "      <td>0 217 137 270 55 209 323 208 731 296 99 79 573...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          frame_id                                     bounding_boxes\n",
       "0  train/A_001.jpg  0 225 214 317 0 172 345 254 285 240 155 131 70...\n",
       "1  train/A_002.jpg  0 254 190 293 0 169 338 271 276 238 160 137 70...\n",
       "2  train/A_003.jpg  0 306 59 241 0 155 306 318 235 233 191 149 713...\n",
       "3  train/A_004.jpg  0 143 239 298 164 223 240 172 721 293 94 76 57...\n",
       "4  train/A_005.jpg  0 217 137 270 55 209 323 208 731 296 99 79 573..."
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ground_truth = pd.read_csv('./train.csv')\n",
    "df_ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nan in bounding boxes\n",
    "df_ground_truth.isna().sum()\n",
    "\n",
    "# Replace nan with [0.0,0.0,0.0,0.0]\n",
    "df_ground_truth = df_ground_truth.fillna('0 0 0 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract HOG features from the training images\n",
    "def extract_features(img):\n",
    "    features, hog_image = hog(img, orientations=12, pixels_per_cell=(8, 8),cells_per_block=(3, 3), visualize=True, channel_axis=-1)\n",
    "    return features\n",
    "\n",
    "# Step 2: Label the HOG features\n",
    "def label_features(features, bounding_boxes):\n",
    "    labels = []\n",
    "    for box in bounding_boxes:\n",
    "        labels.append(1)\n",
    "    return features, labels\n",
    "\n",
    "# Step 3: Train a classifier\n",
    "def train_classifier(features, labels):\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(features, labels)\n",
    "    return clf\n",
    "\n",
    "# Step 4: Extract HOG features from new images\n",
    "def extract_features_from_image(img):\n",
    "    features = extract_features(img)\n",
    "    return features\n",
    "\n",
    "# Step 5: Use the classifier to detect vehicles in new images\n",
    "def detect_vehicles(img, clf):\n",
    "    features = extract_features_from_image(img)\n",
    "    predictions = clf.predict(features)\n",
    "    return predictions\n",
    "\n",
    "# Step 6: Draw the bounding boxes around the detected vehicles\n",
    "def draw_bounding_boxes(img, predictions, bounding_boxes):\n",
    "    for i, pred in enumerate(predictions):\n",
    "        if pred == 1:\n",
    "            x, y, w, h = bounding_boxes[i]\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    return img\n",
    "\n",
    "def annotations_for_frame(df_annotation, frame):\n",
    "    assert frame in df_annotation.index\n",
    "    bbs = df_annotation[df_annotation.index == frame].bounding_boxes.values[0]\n",
    "\n",
    "    if pd.isna(bbs): # some frames contain no vehicles\n",
    "        return []\n",
    "\n",
    "    bbs = list(map(lambda x : int(x), bbs.split(' ')))\n",
    "    return np.array_split(bbs, len(bbs) / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2222/2222 [00:36<00:00, 61.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the training images and their bounding boxes\n",
    "training_images = []\n",
    "bounding_boxes = []\n",
    "\n",
    "for i in tqdm(df_ground_truth.index):\n",
    "    # Save frame_id\n",
    "    frame_id = df_ground_truth.loc[i, 'frame_id']\n",
    "\n",
    "    # Save image\n",
    "    img = cv2.imread(frame_id)\n",
    "\n",
    "    # Save bounding box\n",
    "    train_labels = annotations_for_frame(df_ground_truth, i)\n",
    "\n",
    "    training_images.append(img)\n",
    "    bounding_boxes.append(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HOG features and labels\n",
    "hog_features, labels = tqdm(label_features([extract_features(img) for img in training_images], [box for box in bounding_boxes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat hog_features as new column for df_ground_truth\n",
    "df_ground_truth['hog_features'] = hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_id</th>\n",
       "      <th>bounding_boxes</th>\n",
       "      <th>hog_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/A_001.jpg</td>\n",
       "      <td>[0.0, 225.0, 214.0, 317.0, 0.0, 172.0, 345.0, ...</td>\n",
       "      <td>[0.2371046026703983, 0.2371046026703983, 0.110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/A_002.jpg</td>\n",
       "      <td>[0.0, 254.0, 190.0, 293.0, 0.0, 169.0, 338.0, ...</td>\n",
       "      <td>[0.05479810084769836, 0.029798387772276894, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/A_003.jpg</td>\n",
       "      <td>[0.0, 306.0, 59.0, 241.0, 0.0, 155.0, 306.0, 3...</td>\n",
       "      <td>[0.06389607869122489, 0.019384123841706187, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/A_004.jpg</td>\n",
       "      <td>[0.0, 143.0, 239.0, 298.0, 164.0, 223.0, 240.0...</td>\n",
       "      <td>[0.022722701559013465, 0.0026056156956097525, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/A_005.jpg</td>\n",
       "      <td>[0.0, 217.0, 137.0, 270.0, 55.0, 209.0, 323.0,...</td>\n",
       "      <td>[0.047339984197445666, 0.10008659581998491, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          frame_id                                     bounding_boxes  \\\n",
       "0  train/A_001.jpg  [0.0, 225.0, 214.0, 317.0, 0.0, 172.0, 345.0, ...   \n",
       "1  train/A_002.jpg  [0.0, 254.0, 190.0, 293.0, 0.0, 169.0, 338.0, ...   \n",
       "2  train/A_003.jpg  [0.0, 306.0, 59.0, 241.0, 0.0, 155.0, 306.0, 3...   \n",
       "3  train/A_004.jpg  [0.0, 143.0, 239.0, 298.0, 164.0, 223.0, 240.0...   \n",
       "4  train/A_005.jpg  [0.0, 217.0, 137.0, 270.0, 55.0, 209.0, 323.0,...   \n",
       "\n",
       "                                        hog_features  \n",
       "0  [0.2371046026703983, 0.2371046026703983, 0.110...  \n",
       "1  [0.05479810084769836, 0.029798387772276894, 0....  \n",
       "2  [0.06389607869122489, 0.019384123841706187, 0....  \n",
       "3  [0.022722701559013465, 0.0026056156956097525, ...  \n",
       "4  [0.047339984197445666, 0.10008659581998491, 0....  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform string for each bounding_boxes to a list of floats\n",
    "df_ground_truth['bounding_boxes'] = df_ground_truth['bounding_boxes'].apply(lambda x: np.array([float(i) for i in str(x).split(' ')]))\n",
    "df_ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_ground_truth['hog_features'], df_ground_truth['bounding_boxes'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features = np.array([[2.0,3.0,9.0,8.4],[2.0,3.0,9.0,7.4]])\n",
    "test_target = np.array([[3.0,5.3],[4.0,0.0]])\n",
    "\n",
    "# Create linear regression object\n",
    "regr = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(test_features, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'narray' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/nicolas/Desktop/Etudes/4_centrale_sup/CentraleSupelec/cours/centralesup_S_2/computer_vision/assignments/assign_2/HOG.ipynb Cellule 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nicolas/Desktop/Etudes/4_centrale_sup/CentraleSupelec/cours/centralesup_S_2/computer_vision/assignments/assign_2/HOG.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(y_train,dtype\u001b[39m=\u001b[39mnarray)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nicolas/Desktop/Etudes/4_centrale_sup/CentraleSupelec/cours/centralesup_S_2/computer_vision/assignments/assign_2/HOG.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_train\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'narray' is not defined"
     ]
    }
   ],
   "source": [
    "y_train = np.asarray(y_train)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/nicolas/Desktop/Etudes/4_centrale_sup/CentraleSupelec/cours/centralesup_S_2/computer_vision/assignments/assign_2/HOG.ipynb Cellule 12\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nicolas/Desktop/Etudes/4_centrale_sup/CentraleSupelec/cours/centralesup_S_2/computer_vision/assignments/assign_2/HOG.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m regr \u001b[39m=\u001b[39m LinearRegression()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nicolas/Desktop/Etudes/4_centrale_sup/CentraleSupelec/cours/centralesup_S_2/computer_vision/assignments/assign_2/HOG.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Train the model using the training sets\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nicolas/Desktop/Etudes/4_centrale_sup/CentraleSupelec/cours/centralesup_S_2/computer_vision/assignments/assign_2/HOG.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m regr\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nicolas/Desktop/Etudes/4_centrale_sup/CentraleSupelec/cours/centralesup_S_2/computer_vision/assignments/assign_2/HOG.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Make predictions using the testing set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nicolas/Desktop/Etudes/4_centrale_sup/CentraleSupelec/cours/centralesup_S_2/computer_vision/assignments/assign_2/HOG.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m y_pred \u001b[39m=\u001b[39m regr\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/centrale_computer_vision/lib/python3.10/site-packages/sklearn/linear_model/_base.py:684\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    680\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[1;32m    682\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 684\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    685\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse, y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    686\u001b[0m )\n\u001b[1;32m    688\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(\n\u001b[1;32m    689\u001b[0m     sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype, only_non_negative\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    690\u001b[0m )\n\u001b[1;32m    692\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[39m=\u001b[39m _preprocess_data(\n\u001b[1;32m    693\u001b[0m     X,\n\u001b[1;32m    694\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    698\u001b[0m     sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m    699\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/centrale_computer_vision/lib/python3.10/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/centrale_computer_vision/lib/python3.10/site-packages/sklearn/utils/validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[0;32m-> 1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1075\u001b[0m     X,\n\u001b[1;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1077\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1078\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1079\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1080\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1081\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1082\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1083\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1084\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1085\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1086\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1088\u001b[0m )\n\u001b[1;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/centrale_computer_vision/lib/python3.10/site-packages/sklearn/utils/validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    854\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    855\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    858\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    860\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# Multivariate Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create linear regression object\n",
    "regr = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "        % mean_squared_error(y_test, y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "        % r2_score(y_test, y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(X_test, y_test,  color='black')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "clf = tqdm(train_classifier(hog_features, labels))\n",
    "\n",
    "# Read a new image\n",
    "img = cv2.imread(\"./test/005.jpg\")\n",
    "\n",
    "# Detect vehicles in the new image\n",
    "predictions = detect_vehicles(img, clf)\n",
    "\n",
    "# Draw bounding boxes around the detected vehicles\n",
    "final_image = draw_bounding_boxes(img, predictions, bounding_boxes)\n",
    "\n",
    "# Show the final image\n",
    "cv2.imshow(\"Image\",img)\n",
    "cv2.imshow(\"Detected Vehicles\", final_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "centrale_computer_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Oct 24 2022, 11:04:34) [Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1f9a64cdfff178198a1918802de23deb09209f2bf8660dd97f4435df46bd9d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
